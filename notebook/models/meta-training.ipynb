{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# %%capture\n# !pip install pycaret","metadata":{"execution":{"iopub.status.busy":"2021-07-31T23:48:42.054275Z","iopub.execute_input":"2021-07-31T23:48:42.05491Z","iopub.status.idle":"2021-07-31T23:48:42.059335Z","shell.execute_reply.started":"2021-07-31T23:48:42.054779Z","shell.execute_reply":"2021-07-31T23:48:42.058249Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport copy\nimport random\nimport os\nimport time\n\nfrom sklearn.model_selection import StratifiedKFold, KFold\nfrom sklearn.metrics import mean_squared_error\nfrom hyperopt import fmin, tpe, hp, STATUS_OK, Trials\n\n# from pycaret.regression import *\n\nimport warnings\nwarnings.filterwarnings('ignore')","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2021-07-31T23:48:42.061437Z","iopub.execute_input":"2021-07-31T23:48:42.061884Z","iopub.status.idle":"2021-07-31T23:48:43.523222Z","shell.execute_reply.started":"2021-07-31T23:48:42.061841Z","shell.execute_reply":"2021-07-31T23:48:43.522343Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def set_seed(seed = 0):\n    np.random.seed(seed)\n    random_state = np.random.RandomState(seed)\n    random.seed(seed)\n    os.environ['PYTHONHASHSEED'] = str(seed)\n    return random_state\n\nSEED=912\nrandom_state = set_seed(SEED)","metadata":{"execution":{"iopub.status.busy":"2021-07-31T23:48:43.525369Z","iopub.execute_input":"2021-07-31T23:48:43.526Z","iopub.status.idle":"2021-07-31T23:48:43.533393Z","shell.execute_reply.started":"2021-07-31T23:48:43.525956Z","shell.execute_reply":"2021-07-31T23:48:43.532502Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class ContinuousStratifiedKFold(StratifiedKFold):\n    def split(self, x, y, groups=None):\n        num_bins = int(np.floor(1 + np.log2(len(y))))\n        bins = pd.cut(y, bins=num_bins, labels=False)\n        return super().split(x, bins, groups)","metadata":{"execution":{"iopub.status.busy":"2021-07-31T23:48:43.535126Z","iopub.execute_input":"2021-07-31T23:48:43.535642Z","iopub.status.idle":"2021-07-31T23:48:43.545733Z","shell.execute_reply.started":"2021-07-31T23:48:43.535593Z","shell.execute_reply":"2021-07-31T23:48:43.544694Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train = pd.read_csv('../input/meta-train-data/original_meta_train_data.csv', low_memory=False)\ntrain.drop(train.loc[train['target'] == 0].index, axis=0, inplace=True)\ntrain.reset_index(drop=True, inplace=True)\n\n# train['avg'] = [np.mean([row['m1'], row['m2'], row['m3']]) for _, row in train.iterrows()]\n# train['error'] = [row['target'] - row['avg'] for _, row in train.iterrows()]\n# res = pd.DataFrame({'avg': train['avg'], 'target': train['error']})\n# res.reset_index(drop=True, inplace=True)\n\n# kf = ContinuousStratifiedKFold(n_splits=5, shuffle=True, random_state=SEED)\n# for f, (t_, v_) in enumerate(kf.split(res, res.target)):\n#     res.loc[v_, 'fold'] = f\n# res['fold'] = res['fold'].astype(int)\n\nkf = ContinuousStratifiedKFold(n_splits=5, shuffle=True, random_state=SEED)\nfor f, (t_, v_) in enumerate(kf.split(train, train.target)):\n    train.loc[v_, 'fold'] = f\ntrain['fold'] = train['fold'].astype(int)","metadata":{"execution":{"iopub.status.busy":"2021-07-31T23:48:43.547329Z","iopub.execute_input":"2021-07-31T23:48:43.547772Z","iopub.status.idle":"2021-07-31T23:48:43.620349Z","shell.execute_reply.started":"2021-07-31T23:48:43.547705Z","shell.execute_reply":"2021-07-31T23:48:43.619364Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# def get_data(data, fold):\n#     X_train = data.loc[data.fold != fold, 'avg'].tolist()\n#     y_train = data.loc[data.fold != fold, 'target'].values\n#     X_val = data.loc[data.fold == fold, 'avg'].tolist()\n#     y_val = data.loc[data.fold == fold, 'target'].values\n#     return X_train, y_train, X_val, y_val\n\ndef get_data(data, fold):\n    X_train = data.loc[data.fold != fold, ['m1', 'm2', 'm3']]\n    y_train = data.loc[data.fold != fold, 'target'].values\n    X_val = data.loc[data.fold == fold, ['m1', 'm2', 'm3']]\n    y_val = data.loc[data.fold == fold, 'target'].values\n    return X_train, y_train, X_val, y_val","metadata":{"execution":{"iopub.status.busy":"2021-07-31T23:48:43.621698Z","iopub.execute_input":"2021-07-31T23:48:43.621989Z","iopub.status.idle":"2021-07-31T23:48:43.62824Z","shell.execute_reply.started":"2021-07-31T23:48:43.62196Z","shell.execute_reply":"2021-07-31T23:48:43.627036Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X_t, y_t, X_v, y_v = get_data(train, 0)\nX_t['target'] = y_t\nX_v['target'] = y_v\ntrain_df = copy.deepcopy(X_t)\ntest_df = copy.deepcopy(X_v)\n\n# X_t, y_t, X_v, y_v = get_data(res, 0)\n# train_df = pd.DataFrame({'X': X_t, 'target': y_t})\n# test_df = pd.DataFrame({'X': X_v, 'target': y_v})\n\n# exp = setup(data = train_df, target = 'target', session_id=SEED,\n#             normalize = True, transformation = True, silent=True, \n#             transform_target = True, transform_target_method='yeo-johnson',\n#             remove_outliers=True, polynomial_features=True, \n#             trigonometry_features=True, feature_selection=True, \n#             feature_ratio=True, feature_interaction=True, fold_shuffle=True)","metadata":{"execution":{"iopub.status.busy":"2021-07-31T23:48:43.629826Z","iopub.execute_input":"2021-07-31T23:48:43.630212Z","iopub.status.idle":"2021-07-31T23:48:43.653331Z","shell.execute_reply.started":"2021-07-31T23:48:43.630172Z","shell.execute_reply":"2021-07-31T23:48:43.652397Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# all_models = compare_models(n_select=12, exclude=['xgboost', 'catboost'])","metadata":{"execution":{"iopub.status.busy":"2021-07-31T23:48:43.654629Z","iopub.execute_input":"2021-07-31T23:48:43.654971Z","iopub.status.idle":"2021-07-31T23:48:43.66092Z","shell.execute_reply.started":"2021-07-31T23:48:43.654933Z","shell.execute_reply":"2021-07-31T23:48:43.659917Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# finalized_models = []\n# for _, model in enumerate(all_models[:10]):\n#     fine_tuned = tune_model(model)\n#     finalized = finalize_model(fine_tuned)\n#     finalized_models.append(finalized)","metadata":{"execution":{"iopub.status.busy":"2021-07-31T23:48:43.663182Z","iopub.execute_input":"2021-07-31T23:48:43.663469Z","iopub.status.idle":"2021-07-31T23:48:43.672446Z","shell.execute_reply.started":"2021-07-31T23:48:43.66344Z","shell.execute_reply":"2021-07-31T23:48:43.67152Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# X_test = copy.deepcopy(test_df)\n# X_test.drop(columns=['target'], axis=1, inplace=True)\n# y_test = copy.deepcopy(test_df['target'])\n\n# best_single_estimator = finalized_models[0]\n# y_pred = predict_model(estimator=best_single_estimator, data=X_test)\n\n# print(f'* best_single model rmse: {mean_squared_error(y_test, y_pred.Label.values, squared=False)}')","metadata":{"execution":{"iopub.status.busy":"2021-07-31T23:48:43.673834Z","iopub.execute_input":"2021-07-31T23:48:43.674124Z","iopub.status.idle":"2021-07-31T23:48:43.683943Z","shell.execute_reply.started":"2021-07-31T23:48:43.674088Z","shell.execute_reply":"2021-07-31T23:48:43.682812Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# X_train = copy.deepcopy(train_df)\n# X_train.drop(columns=['target'], axis=1, inplace=True)\n# y_train = copy.deepcopy(train_df['target'])\n\n# print(f\"* X_Train shape: {X_train.shape} y_train shape: {y_train.shape}\")\n\n# blend_map = {}\n# def cross_val_score(estimator, n_splits=5, random_state=SEED):\n#     cv = KFold(n_splits=n_splits, shuffle=True, random_state=random_state)\n#     cv_iter = list(cv.split(X_train, y_train))\n#     scores = []\n#     for train_index, test_index in cv_iter:\n#         y_true = y_train.iloc[test_index]\n#         y_pred = predict_model(estimator=estimator, data=X_train.iloc[test_index,:])\n#         scores.append(mean_squared_error(y_true, y_pred.Label.values, squared=False))\n#     return np.array(scores).mean()\n\n# def hyperopt_train_test(estimator_list):\n#     estimator = blend_models(estimator_list=[finalized_models[i] for i in estimator_list], choose_better = True, fold=3)\n#     res = cross_val_score(estimator).mean()\n#     blend_map[time.time()] = (estimator, res)\n#     return res\n\n# def optimise(params):\n#     estimator_list = []\n#     for key, val in params.items():\n#         if val == 1:\n#             estimator_list.append(int(key))\n#     rmse = hyperopt_train_test(estimator_list)\n#     return {'loss': rmse, 'status': STATUS_OK}\n\n# model_selection_space = {\n#     '0': hp.choice('0', [0, 1]),\n#     '1': hp.choice('1', [0, 1]),\n#     '2': hp.choice('2', [0, 1]),\n#     '3': hp.choice('3', [0, 1]),\n#     '4': hp.choice('4', [0, 1]),\n#     '5': hp.choice('5', [0, 1]),\n#     '6': hp.choice('6', [0, 1]),\n#     '7': hp.choice('7', [0, 1]),\n#     '8': hp.choice('8', [0, 1]),\n#     '9': hp.choice('9', [0, 1]),\n# }\n\n# blend_trials = Trials()\n# blend_best = fmin(optimise, model_selection_space, algo=tpe.suggest, max_evals=30, trials=blend_trials, rstate=random_state)\n\n# best_blend_res = float('inf')\n# best_blend_key = 0\n# for k, v in blend_map.items():\n#     if v[1] < best_blend_res:\n#         best_blend_key = k\n#         best_blend_res = v[1]\n\n# X_test = copy.deepcopy(test_df)\n# X_test.drop(columns=['target'], axis=1, inplace=True)\n# y_test = copy.deepcopy(test_df['target'])\n\n# blend_estimator = blend_map[best_blend_key][0]\n# y_pred = predict_model(estimator=blend_estimator, data=X_test)\n\n# print(f'* Blend model rmse: {mean_squared_error(y_test, y_pred.Label.values, squared=False)}')\n\n# model_path = '/kaggle/working/blend_estimator'\n# model, path = save_model(blend_estimator, model_path)","metadata":{"execution":{"iopub.status.busy":"2021-07-31T23:48:43.685178Z","iopub.execute_input":"2021-07-31T23:48:43.685466Z","iopub.status.idle":"2021-07-31T23:48:43.695196Z","shell.execute_reply.started":"2021-07-31T23:48:43.685439Z","shell.execute_reply":"2021-07-31T23:48:43.694128Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# X_train = copy.deepcopy(train_df)\n# X_train.drop(columns=['target'], axis=1, inplace=True)\n# y_train = copy.deepcopy(train_df['target'])\n\n# print(f\"* X_Train shape: {X_train.shape} y_train shape: {y_train.shape}\")\n\n# stack_map = {}\n# def cross_val_score(estimator, n_splits=5, random_state=SEED):\n#     cv = KFold(n_splits=n_splits, shuffle=True, random_state=random_state)\n#     cv_iter = list(cv.split(X_train, y_train))\n#     scores = []\n#     for train_index, test_index in cv_iter:\n#         y_true = y_train.iloc[test_index]\n#         y_pred = predict_model(estimator=estimator, data=X_train.iloc[test_index,:])\n#         scores.append(mean_squared_error(y_true, y_pred.Label.values, squared=False))\n#     return np.array(scores).mean()\n\n# def hyperopt_train_test(estimator_list, meta_index):\n#     estimator = stack_models(estimator_list=[finalized_models[i] for i in estimator_list], fold=3, meta_model=finalized_models[meta_index], choose_better = True)\n#     res = cross_val_score(estimator).mean()\n#     stack_map[time.time()] = (estimator, res)\n#     return res\n\n# def optimise(params):\n#     meta_index = params.pop('meta')\n#     estimator_list = []\n#     for key, val in params.items():\n#         if val == 1:\n#             estimator_list.append(int(key))\n#     rmse = hyperopt_train_test(estimator_list, meta_index)\n#     return {'loss': rmse, 'status': STATUS_OK}\n\n\n# model_selection_space = {\n#     '0': hp.choice('0', [0, 1]),\n#     '1': hp.choice('1', [0, 1]),\n#     '2': hp.choice('2', [0, 1]),\n#     '3': hp.choice('3', [0, 1]),\n#     '4': hp.choice('4', [0, 1]),\n#     '5': hp.choice('5', [0, 1]),\n#     '6': hp.choice('6', [0, 1]),\n#     '7': hp.choice('7', [0, 1]),\n#     '8': hp.choice('8', [0, 1]),\n#     '9': hp.choice('9', [0, 1]),\n#     'meta': hp.choice('meta', [0, 1, 2, 3, 4, 5, 6, 7, 8, 9])\n# }\n\n# stack_trials = Trials()\n# stack_best = fmin(optimise, model_selection_space, algo=tpe.suggest, max_evals=30, trials=stack_trials, rstate=random_state)\n\n# best_stack_res = float('inf')\n# best_stack_key = 0\n# for k, v in stack_map.items():\n#     if v[1] < best_stack_res:\n#         best_stack_key = k\n#         best_stack_res = v[1]\n\n# X_test = copy.deepcopy(test_df)\n# X_test.drop(columns=['target'], axis=1, inplace=True)\n# y_test = copy.deepcopy(test_df['target'])\n\n# stack_estimator = stack_map[best_stack_key][0]\n# y_pred = predict_model(estimator=stack_estimator, data=X_test)\n\n# print(f'* Stack model rmse: {mean_squared_error(y_test, y_pred.Label.values, squared=False)}')\n\n\n# model_path = '/kaggle/working/stack_estimator'\n# model, path = save_model(stack_estimator, model_path)","metadata":{"execution":{"iopub.status.busy":"2021-07-31T23:48:43.696538Z","iopub.execute_input":"2021-07-31T23:48:43.696986Z","iopub.status.idle":"2021-07-31T23:48:43.712895Z","shell.execute_reply.started":"2021-07-31T23:48:43.696934Z","shell.execute_reply":"2021-07-31T23:48:43.711648Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# model_path = '/kaggle/working/best_estimator'\n# model, path = save_model(finalized_models[0], model_path)","metadata":{"execution":{"iopub.status.busy":"2021-07-31T23:48:43.715872Z","iopub.execute_input":"2021-07-31T23:48:43.7162Z","iopub.status.idle":"2021-07-31T23:48:43.727839Z","shell.execute_reply.started":"2021-07-31T23:48:43.716168Z","shell.execute_reply":"2021-07-31T23:48:43.726892Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X_train = copy.deepcopy(train_df)\nX_train.drop(columns=['target'], axis=1, inplace=True)\ny_train = copy.deepcopy(train_df['target'])\n\nprint(f\"* X_Train shape: {X_train.shape} y_train shape: {y_train.shape}\")\n\ndef cross_val_score(X, Y, Z, n_splits=5, random_state=SEED):\n    cv = KFold(n_splits=n_splits, shuffle=True, random_state=random_state)\n    cv_iter = list(cv.split(X_train, y_train))\n    scores = []\n    for train_index, test_index in cv_iter:\n        y_true = y_train.iloc[test_index]\n        temp = X_train.iloc[test_index,:]\n        y_pred = (temp['m1'] * X) + (temp['m2'] * Y) + (temp['m3'] * Z)\n        scores.append(mean_squared_error(y_true, y_pred, squared=False))\n    return np.array(scores).mean()\n\ndef hyperopt_train_test(X, Y, Z):\n    return cross_val_score(X, Y, Z)\n\ndef optimise(params):\n    X = params.get('X')\n    Y = params.get('Y')\n    Z = params.get('Z')\n    rmse = hyperopt_train_test(X, Y, Z)\n    return {'loss': rmse, 'status': STATUS_OK}\n\n\nparam_space = {\n    'X': hp.loguniform('X', np.log(0.0001), np.log(0.9)),\n    'Y': hp.loguniform('Y', np.log(0.0001), np.log(0.9)),\n    'Z': hp.loguniform('Z', np.log(0.0001), np.log(0.9)),\n}\n\ntrials = Trials()\nbest = fmin(optimise, param_space, algo=tpe.suggest, max_evals=20000, trials=trials, rstate=random_state)\nprint(best)\nX_test = copy.deepcopy(test_df)\nX_test.drop(columns=['target'], axis=1, inplace=True)\ny_test = copy.deepcopy(test_df['target'])\n\ny_pred = (X_test['m1'] * best.get('X')) + (X_test['m2'] * best.get('Y')) + (X_test['m3'] * best.get('Z')) \n\nprint(f'* best rmse: {mean_squared_error(y_test, y_pred, squared=False)}')\n\n# * X_Train shape: (2266, 3) y_train shape: (2266,)\n# 100%|██████████| 20000/20000 [1:45:05<00:00,  3.17trial/s, best loss: 0.08548933236554794]\n# {'X': 0.00015000387489372483, 'Y': 0.1143697711814775, 'Z': 0.8894452627596913}\n# * best rmse: 0.09701197982575435","metadata":{"execution":{"iopub.status.busy":"2021-07-31T23:48:43.728969Z","iopub.execute_input":"2021-07-31T23:48:43.729255Z","iopub.status.idle":"2021-08-01T01:33:49.349831Z","shell.execute_reply.started":"2021-07-31T23:48:43.729228Z","shell.execute_reply":"2021-08-01T01:33:49.34869Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# error = predict_model(estimator=finalized_models[0], data=pd.DataFrame({'X': train['avg'][:10].values}))\n# pred = train['avg'][:10].values + error.Label.values\n# mean_squared_error(train['target'][:10].values, pred, squared=False)","metadata":{"execution":{"iopub.status.busy":"2021-08-01T01:33:49.351213Z","iopub.execute_input":"2021-08-01T01:33:49.351522Z","iopub.status.idle":"2021-08-01T01:33:49.356088Z","shell.execute_reply.started":"2021-08-01T01:33:49.351483Z","shell.execute_reply":"2021-08-01T01:33:49.355129Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# mean_squared_error(train['target'][:10].values, train['avg'][:10].values, squared=False)","metadata":{"execution":{"iopub.status.busy":"2021-08-01T01:33:49.357075Z","iopub.execute_input":"2021-08-01T01:33:49.357354Z","iopub.status.idle":"2021-08-01T01:33:49.368618Z","shell.execute_reply.started":"2021-08-01T01:33:49.357327Z","shell.execute_reply":"2021-08-01T01:33:49.367443Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}